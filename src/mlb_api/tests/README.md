# MLB API Data Validation Tests

Comprehensive test suite for validating data accuracy across all MLB API collectors.

## Test Structure

```
src/mlb_api/tests/
â”œâ”€â”€ __init__.py              # Package initialization
â”œâ”€â”€ data_validation.py       # Main validation test suite
â”œâ”€â”€ run_tests.py            # Simple test runner
â”œâ”€â”€ summary.py              # Results summary display
â””â”€â”€ README.md               # This file
```

## Test Output

Test results are saved to:
```
/mnt/storage_fast/workspaces/red_ocean/_data/mlb_api_2025/tests/
â””â”€â”€ validation_results_YYYYMMDD_HHMMSS.json
```

## Test Coverage

### 1. Roster Data Validation
- âœ… Team count validation (30 teams)
- âœ… Player count validation (20-30 players per team)
- âœ… Data structure validation
- âœ… Metadata validation

### 2. Statcast Data Validation
- âœ… Date files validation (100+ date files)
- âœ… Player data validation
- âœ… Data freshness validation
- âœ… Structure validation

### 3. Rolling Windows Data Validation
- âœ… Player files validation (700+ player files)
- âœ… Hash files validation
- âœ… Data structure validation
- âœ… Window sizes validation (50, 100, 250)

### 4. Cross-Reference Validation
- âœ… Player count consistency
- âœ… Team consistency
- âœ… Player ID overlap validation
- âœ… Data freshness comparison

## Usage

### Run All Tests
```bash
python src/mlb_api/tests/run_tests.py
```

### View Latest Results Summary
```bash
python src/mlb_api/tests/summary.py
```

### Run Individual Test
```python
from mlb_api.tests.data_validation import DataValidator

validator = DataValidator()
summary = validator.run_all_tests()
```

## Expected Data Patterns

- **Teams**: 30 MLB teams
- **Players per team**: 20-30 players
- **Statcast dates**: 100+ date files
- **Rolling players**: 700+ player files
- **Data overlap**: 80%+ consistency between datasets

## Test Results Interpretation

### Success Criteria
- âœ… **All tests pass** (0 errors)
- âœ… **High data consistency** (95%+ overlap)
- âœ… **Expected data volumes** met
- âœ… **Data structure** valid

### Warning Levels
- âš ï¸ **Minor warnings**: Non-critical issues (e.g., missing directories)
- âš ï¸ **Data freshness**: Data older than expected
- âš ï¸ **Volume warnings**: Lower than expected data volumes

### Error Levels
- âŒ **Critical errors**: Missing required data or structure
- âŒ **Validation failures**: Data doesn't meet expected patterns
- âŒ **Consistency errors**: Major discrepancies between datasets

## Recent Test Results

**Latest Run**: 2025-08-13 17:16:06
- âœ… **4/4 tests passed** (100% success rate)
- âœ… **0 errors**
- âš ï¸ **2 warnings** (non-critical)
- ğŸ‰ **Excellent data consistency** (100% overlap)

### Data Quality Metrics
- ğŸŸï¸ **MLB Teams**: 30/30
- ğŸ‘¥ **Active Players**: 780
- ğŸ“Š **Rolling Data Files**: 791
- ğŸ”— **Data Consistency**: 100.0% overlap

## Continuous Integration

These tests can be integrated into CI/CD pipelines to ensure data quality:

```bash
# Exit with error code if tests fail
python src/mlb_api/tests/run_tests.py
if [ $? -eq 0 ]; then
    echo "âœ… All tests passed"
else
    echo "âŒ Tests failed"
    exit 1
fi
```

## Customization

You can customize test parameters by modifying the `expected_patterns` in `DataValidator`:

```python
self.expected_patterns = {
    'teams_count': 30,
    'players_per_team_min': 20,
    'players_per_team_max': 30,
    'statcast_dates_min': 100,
    'rolling_players_min': 700
}
```
